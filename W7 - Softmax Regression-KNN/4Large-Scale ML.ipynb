{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Outline**\n",
    "\n",
    "In this notebook, we study how to handle **large-scale datasets** in sklearn.\n",
    "\n",
    "* In this course, so far we were able to load entire data in memory and were able to train and make inferences on all the data at once.\n",
    "\n",
    "* The large scale data sets may not fit in memory and we need to devise strategies to handle it in the context of training and prediction use cases.\n",
    "\n",
    "In this notebook, we will discuss the following topics :\n",
    "\n",
    "* Overview of handling large-scale data.\n",
    "\n",
    "* Incremental preprocessing and learning i.e. `fit()` vs `partial_fit()` : `partial_fit` is our friend in this cases.\n",
    "\n",
    "* Combining preprocessing and incremental learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Large-scale Machine Learning**\n",
    "\n",
    "* Large-scale Machine Learning differs from traditional machine learning in the sense that it involves processing large amount of data in terms of its **size** or **number of samples, features or classes** \n",
    "\n",
    "* There were many exciting developements in efficient large scale learning on many real world use cases in the last decade.\n",
    "\n",
    "* Although scikit-learn is optimized for **smaller data**, it does offer a decent set of **feature preprocessing** and **learning algorithms** for large scale data such as classification, regression and clustering.\n",
    "\n",
    "* Scikit-learn handles large data through `partial_fit()` method instead of using the usual `fit()` method. \n",
    "\n",
    "The idea is to process data in **batches** and **update** the model parameters for each batch. This way of learning is referred to as **Incremental (or out-or-core) learning**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Incremental Learning** \n",
    "\n",
    "Incremental learning may be required in the following two scenarios :\n",
    "\n",
    "* For **out-of-memory (large) datasets** ,where it's not possible to **load the entire data into the RAM** at once, one can load the data in chunks and fit the training model for each chunk of data.\n",
    "\n",
    "* For machine learning tasks where a new batch of data comes with time,re-training the model with the previous and new batch of data is a computationally expensive process.\n",
    "\n",
    "Instead of re-training the model with the entire set of data, one can employ an incremental learning approach, where the model parameters are updated with the new batch of data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Incremental Learning in `sklearn`**\n",
    "\n",
    "To perform incremental learning, Scikit-learn implements `partial_fit` method that helps in training an out-of-memory dataset. \n",
    "\n",
    "In other words, it has the ability to learn incrementally from a batch of instances.\n",
    "\n",
    "In this notebook, we will see an example of how to read, process, and train on such a large dataset that can't be loaded in memory entirely.\n",
    "\n",
    "This method is expected to be called several times consecutively on different chunks of a dataset so as to implement out-of-core (online) learning. \n",
    "\n",
    "This function has some performance overhead, so it's recommended to call it on a considerable large batch of data(that fits into the memory), to overcome the limitation of overhead.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **partial_fit() attributes :**\n",
    "\n",
    "`partial_fit(X,y,[classes], [sample_weight])`\n",
    "\n",
    "where,\n",
    "\n",
    "* `X` : array of shape(n_samples, n_features) where **n_samples** is the number of samples & **n_features** is the number of features. \n",
    "\n",
    "* `y` : array of shape (n_samples,) of target values.\n",
    "\n",
    "* `classes`: array of shape(n_classes,) containing a list of all the classes that can possibly appear in the y vector. Must be provided at the first call to partial_fit, can be omitted in subsequet calls.\n",
    "\n",
    "* sample_`weight`: (optional) array of shape(n_samples,) containing weights applied to individual samples(1.for unweighted)\n",
    "\n",
    "**Returns**: object(self) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "For classification tasks, we have to pass the list of possible target class labels in `classes` parameter to cope-up with the unseen target classes in the 1st batch of the data.\n",
    "\n",
    "The following estimators implement partial_fit method :\n",
    "\n",
    "* **Classification** :\n",
    "  * MultinomialNB \n",
    "\n",
    "  * BernoulliNB \n",
    "\n",
    "  * SGDClassifier\n",
    "  \n",
    "  * Perceptron \n",
    "\n",
    "* **Regression** :\n",
    "  * SGDRegressor\n",
    "\n",
    "\n",
    "* **Clustering** :\n",
    "  * `MiniBatchKmean`\n",
    "\n",
    "`SGDRegressor` and `SGDClassifier` are commonly used for handling large data.\n",
    "\n",
    "The problem with standard regression / classification implementations such as **batch gradient descent, support vector machines (SVMs), random forest** etc. is that because of the need to load all the data into memory at once, they can not be used in scenarios where we do not have sufficient memory. \n",
    "\n",
    "SGD, however, can deal with large data sets effectively by breaking up the data into chunks and processing them sequentially. \n",
    "\n",
    "The fact that we only need to load one chunk into memory at a time makes it useful for large-scale data as well as cases where we get streams of data at intervals.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **fit() versus partial_fit()**\n",
    "\n",
    "Below, we show the use of `partial_fit()` along with `SGDClassifier`.\n",
    "\n",
    "For the purpose of illustration, we first use traditional `fit()` and then use `partial_fit()` on the same data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Importing Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Libraries\n",
    "\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns \n",
    "\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report ,ConfusionMatrixDisplay\n",
    "\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Traditional Approach [using fit()]**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sample dataset**\n",
    "\n",
    "We will use a synthetic classification dataset for demonstration.\n",
    "Let us have 50000 samples with 10 features matrix. \n",
    "\n",
    "Further, lets have 3 classes in the target label, each class having a single cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_classification(n_samples=50000, n_features=10,\n",
    "                           n_classes=3,\n",
    "                           n_clusters_per_class=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will make use of `SGDClassifier` to learn the classification model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf1 = SGDClassifier(max_iter=1000, tol=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use traditional `fit()` method to train out model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SGDClassifier(tol=0.01)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SGDClassifier</label><div class=\"sk-toggleable__content\"><pre>SGDClassifier(tol=0.01)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SGDClassifier(tol=0.01)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's obtain the training and test scores on the trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9223764705882352"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_score = clf1.score(X_train, y_train)\n",
    "train_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9224"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_score = clf1.score(X_test, y_test)\n",
    "test_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We obtain the confusion matrix and classification report for evaluating the classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAT8AAAEGCAYAAAAT05LOAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAjs0lEQVR4nO3deXhU5fn/8fedEJKwJBAg7IhKQEEULYKoRVyKQNuf69da26p1wfVbrbRWra2tS7VfW60tLnVBa92tWtGqiFar1gVZVBZFNtkRQiAEErLM3L8/5gSCQjJDMswk5/O6rnNl5pmz3GdIbp7lnOeYuyMiEjYZqQ5ARCQVlPxEJJSU/EQklJT8RCSUlPxEJJRapTqAujoXZHrf3lmpDiNtff5Jm1SHkP7MUh1BWtvqW6jyrY36ko4/uq2vL4nEte6MTyqnuPuYxhwvWdIq+fXtncW0Kb1THUbaOr7HkFSHkPYsOzvVIaS19ytfbvQ+iksifDClV1zrZnVf1LnRB0yStEp+ItIcOBGPpjqIRlPyE5GEOBCl+d8coeQnIgmLopqfiISM41Sr2SsiYeNARM1eEQkj9fmJSOg4EGkBs0Ep+YlIwpp/j5+Sn4gkyHH1+YlI+LhDdfPPfUp+IpIoI0Lzv4dayU9EEuJAVDU/EQkj1fxEJHRiFzkr+YlIyDhQ7c1/HmQlPxFJiGNEWsAk8Ep+IpKwqKvZKyIhoz4/EQkpI6I+PxEJm9hMzkp+IhIy7kaVZ6Y6jEZT8hORhEXV5yciYRMb8FCzV0RCRwMeIhJCGvAQkdCK6CJnEQkbx6j25p86mv8ZiMgepQEPEQklx9TsFZFw0oBHM7N2ZRa3XtaHjeuywJxxP1zPSecVb/v8H/d04b7re/LU7Nnkd4oA8PG77bjn1z2pqYH8ggh/eHYhAJtLM7n9Z7354rMczOCK25YxcGh5Ss4rFU48dx1jf1CCmfPyo5147v4uqQ4p5dq2r+Hy3y+hb/8K3OH2K/dm+eJcrpm4kK49K/lyZTa/u6Qfmzc17z87d3SpS0PMbAxwB5AJ3O/utyTzeA3JbOWM//Uqig6soHxzBpeO6c8hI8vYq38la1dmMfM/7SnsWbVt/c2lmUy8uhc3PbqIwl7VbCze/nXd/eueDB21iV/d9wXVVUZlRfP/ZYjXXgMqGPuDEn7y7SKqq4zfPbaYD17LY9UX2akOLaUuvG4pM/6Tz00XF9EqK0p2TpTTL1nFR//N46l7enDahas47aLVTPp971SH2iixAY/mf3tb0v5izSwTuBMYCwwEvm9mA5N1vHh06lpD0YEVALRpF6V3v0qKV2cB8Nff9OTca1dhdboy3niuA0eM20hhr2oAOnSuAWDLpgxmv9+WMWeUAJDV2mmXH9mDZ5JafYoq+WxWGyorMohGjE/ea8cR40pTHVZKtWlfw+BhZbzyZKwGXFOdwZayVoz41kZee6YzAK8905nDR29IZZhNJkJGXEs6S2Z0w4CF7r7Y3auAJ4ATkni8hKxZ3ppFc3LZ75By3n0lj87dqtl30NYd1lmxOIfNGzP5+Sn9uOT4/kx9umNs22XZ5Heq4Y8/7cPF3+rP7RN6s7U8vf+hm9IXn+VwwLDNtO9YQ3ZulEOP2USXHlUNb9iCdetVSWlJFhNuXcLEF+dw+S1LyM6N0KFzNSXrWgNQsi6LDp2rUxxp4zlG1ONb0lky/2J7AsvrvF8RlKVcxZYMbjivLxdev5LMTOeJv3TlzJ+v/tp6kRpYMLsNN/x9Mb97bBGP/akbKxZlE4nAwtlt+M6Zxdw19XNy2kR5cmJhCs4kNZYvzOGpuwq5+fHF3PToYhbPzSUaSe9f9GTLbOX0G7SFFx8t5NLvHMDW8gy+d9FXf6cMbwGPfATV/JqEmY03s+lmNn3d+uQ3HWuq4Ybz+nLMyRs4clwpq5dms2ZZay46bj/OHDaQdauzuOT4AZSsbUWX7tV846gyctpEye8UYfDwzSyel0Pn7tV06V7NfofEBjiO/M5GFs7OTXrs6WTK4524dEx/fnZyPzaXZrJicbj7+4pXt6Z4TWvmf9QOgLdfLqDfoC1sLM6ioEusVlzQpYrS9VmpDLNJxJ7bmxHXks6SGd1KoG7Pbq+gbAfufq+7D3X3oV06JbcT1R1um9CH3kWVnHLBOgD23n8rT82ey8PT5vHwtHl06V7NnVPmU1BYw4gxpcz9sC2RGthabnw2qw19iiopKKyhc48qli+M/cF/9HZ7+hRVJjX2dJPfKdZ869KziiPGlfLGcx1THFFqbShuzbrVrem1T6xP+eDDS1m2MJf3X+vAcafErig47pRi3pvaIYVRNhUjEudS717MepvZG2Y2z8zmmtllQXmBmU01swXBz45BuZnZn81soZl9YmaH1NnXWcH6C8zsrHjOIpmjvR8CRWa2N7GkdzpwRhKP16C509ry+j8K2Hv/Ci46bgAAP756FcOOLdvp+n2KKhk6ahMXHrsfluGMOaOEvvvF+gUvuXElv790L2qqjW59qphw+7I9dh7p4Nf3L6V9xxoi1cbEa3qyZVPzH/1rrLuu24srb19EVmtn9bJsbvv5PliGc83ERRx/2jrWrszmpkv7pTrMRos9urJJ/r1rgAnuPtPM2gMzzGwqcDbwurvfYmZXAVcBvyA2eFoULMOBu4HhZlYAXAcMDcKbYWaT3b3e0SXzJHZCmNk44E/ELnWZ5O431bf+0INyfNqU5n0ZQDId32NIqkNIe5Yd7uZ3Q96vfJlN0fWN6qDtOaiDX/zUkXGte+0B/5rh7kPjWdfMngcmBssod19tZt2BN919gJn9NXj9eLD+fGBU7eLuFwTlO6y3K0m9zs/dXwJeSuYxRGTPa+qLnM2sL3Aw8AHQ1d1rR4vWAF2D17saRN2twdXmfam5iOxxsfn84q48djaz6XXe3+vu99ZdwczaAc8Al7v7Jqtzsa27u5klpXmq5CciCUpoJufi+pq9ZpZFLPE96u7PBsVfmln3Os3etUH5rgZRVxJr+tYtf7OhwNJ7LFpE0k7sUpfGX+RssSreA8Cn7n5bnY8mA7UjtmcBz9cpPzMY9T0MKA2ax1OA0WbWMRgZHh2U1Us1PxFJSBPe23sE8CNgtpl9FJRdA9wCPGVm5wJLgdOCz14CxgELgXLgxwDuXmJmNxC7wgTgencvaejgSn4ikrCmmNLK3d+BXXYeHruT9R24ZBf7mgRMSuT4Sn4ikpDYlFbN/3ZGJT8RSVi6T1oQDyU/EUlIbFaX5j9WquQnIgmJ3d6m5CcioaOan4iEVAJ3eKQtJT8RSYhGe0UktNTsFZHQqX2GR3On5CciCXGgRjU/EQkjNXtFJHyawWMp46HkJyIJSXAy07Sl5CciCVPNT0RCp3Yy0+ZOyU9EEuIYNVENeIhICKnPT0TCx9XsFZEQUp+fiISWkp+IhI5jRDTgISJhpAEPEQkd14CHiISVK/mJSPhoYgMRCSnV/JrYgrntGTfo6FSHkbYeWvZCqkNIe2f3OTLVIaQ39ybZRSSq5CciIaTRXhEJHUfNXhEJJQ14iEhINUHXYcop+YlIwtTsFZHQiY326t5eEQkhNXtFJJTU7BWR0HGsRSS/5t9wF5E9zuNcGmJmk8xsrZnNqVP2GzNbaWYfBcu4Op9dbWYLzWy+mR1fp3xMULbQzK6K5xyU/EQkMQ4etbiWODwEjNlJ+e3uPiRYXgIws4HA6cCgYJu7zCzTzDKBO4GxwEDg+8G69VKzV0QS1lTNXnd/y8z6xrn6CcAT7l4JLDGzhcCw4LOF7r4YwMyeCNadV9/OVPMTkYS5x7cAnc1sep1lfJyHuNTMPgmaxR2Dsp7A8jrrrAjKdlVer13W/MzsL9TTbHf3nzS0cxFpeRK8t7fY3YcmeIi7gRuCQ90A/BE4J8F9NKi+Zu/0pj6YiLQADiRxtNfdv6x9bWb3AS8Gb1cCveus2isoo57yXdpl8nP3v9V9b2Zt3L28oR2KSMuXzIuczay7u68O3p4E1I4ETwYeM7PbgB5AETANMKDIzPYmlvROB85o6DgNDniY2QjgAaAd0MfMDgIucPeLEzslEWkZ4h7JbXhPZo8Do4j1Da4ArgNGmdkQYnXML4ALANx9rpk9RWwgowa4xN0jwX4uBaYAmcAkd5/b0LHjGe39E3A8sayLu39sZiPjPz0RaXGaqObn7t/fSfED9ax/E3DTTspfAl5K5NhxXeri7svNdsj0kUQOIiItiIfn9rblZnY44GaWBVwGfJrcsEQkrbWAiQ3iuc7vQuASYtfNrAKGBO9FJLQsziV9NVjzc/di4Ad7IBYRaS6iqQ6g8Rqs+ZnZPmb2gpmtC25Aft7M9tkTwYlIGqq9zi+eJY3F0+x9DHgK6E7s2pqngceTGZSIpLcEbm9LW/Ekvzbu/nd3rwmWR4CcZAcmImmsqea0SqH67u0tCF6+HMyP9QSx0/keCV5PIyItTJo3aeNR34DHDGLJrvYsL6jzmQNXJysoEUlvlua1unjUd2/v3nsyEBFpJtygiW5vS6W47vAwswOIzZC6ra/P3R9OVlAikuZacs2vlpldR+zG44HE+vrGAu8ASn4iYdUCkl88o72nAscCa9z9x8BBQH5SoxKR9NaSR3vrqHD3qJnVmFkesJYdJw5sli6/4TOGHbWejSVZXHxi7DEA50xYxPBRxdRUZ7B6eS63XzuALWVZZLaKctn18+m3/2YyMp1/T+7KU/fvleIzaHrrV7Xmvp/2Z9O61mDOqDO+ZPS5q3jmD32Y9WonLMPJ61TNeX9cQMduVQB8+l4+j/12byLVRvuCGq5+ejYAU+7vwX8e74oZ9NqvnHP/8Dmtc9L8r6GRrrhtGcOPK2NjcSsuOGYAAD+csIaxZ6yntCT2p/bgzd358N95qQyz8ZI8memeEk/ym25mHYD7iI0Abwbea2gjM5sEfAdY6+4HNCbIZHjtn9144bGeTLh5+xwNs97ryEN/2ptoJIMfX7GI085fxoO37cs3j19HVlaUi086lOycCPdMnsabLxWydlVuCs+g6WVmOqdfu4S+g7dQsTmT33x7CIO+uYFxF6zklJ8tA2DqpO48f0dvzr55EVtKM/n7L/dlwt/n0qlnJZuKswDYsKY1Ux/swe9en0nrnCh3XjSAD17owjf/Z20qTy/pXn2ygMkPdubndyzfofy5+7rwj3sKUxRVcrSE0d4Gm73ufrG7b3T3e4BvAWcFzd+GPMTOH0mXFubM6EBZ6Y65f9a7BUQjsa/ks4/z6Ny1EohdqZ7TJkpGZpTW2VFqqjMo39LyHnzXoWs1fQdvASC3XYQe/crZsCab3PbbZzCrLM+kdnaz95/vwjfGFtOpZ+x7yutcvW29aI1RtTWDSA1UVWTSsWvVnjuRFJnzQTvKNrS834udasnNXjM7pL7P3H1mfTtO8JF0aWf0yWt46+UuALzzahcOO7qYR998j+ycCPf+Xz82l2alOMLkWrc8m6Vz27LvwWUA/OP/9uLdZwrJbV/DL56MNW3XLM4lUmPcfNpgtm7OZPQ5qzji1LV07FbFmPErmXDYobTOiTJo5AYOGLkxhWeTWt/9cTHHnrqBBZ/kcu9ve7C5tPknyJZQ86vvX+GP9XzmwDFNEUDwKLvxADkZ7Zpil432vfFLidQYb7zYFYABg8uIRo0fHj2Cdnk13PrwLD56ryNrVrSsZm+trVsymHjB/pxx3ZJttb5Tr1zKqVcu5cWJvXj9oR6cNGEZ0Yjxxex2/OLxOVRtzeDGEw9i30M20b6gmllTC7j1vx/SJi/CnRftx7vPduHwk9el+Mz2vBf/1onHbu+KO5x15RrGX7eK267ok+qwGq8F9Pntstnr7kfXszRJ4guOc6+7D3X3oa0t9bcMH3fiaoYdtZ5bf7E/tTe3jPr2l8x4p4BITQalJa2ZNyufokFlqQ00SWqqjYkX7M+Ik9YydOz6r30+4qR1TH+5EwAdu1UxeORGsttEaV9QQ//hpSyb15a573Sgc++t5HWqoVWWM3TMehbOaOad/LtpY3EW0ajhbrz8aCcGDKlIdUiNF2+TN81rh3poeR3fOHI9p56znN9eegCVWzO3la9dncNBwzcCkJ0bYb+DNrF8SZsURZk87jDp50V071fOmPNXbStfs2T7f0ozXy2g+76xP+BDRq/n8w/ziNRAZUUGi2e1p0dRBZ16VrJoZnsqKzJwh3n/zad7v3A++K+gcHs/6OFjS/lifur/g28SLSD5Nf/Oh9105a3zOPDQjeR1qObh19/lkTv35rTzl5KV5dx0/8cAzP84j4nXD+DFx3vw0xvnc/fz0zCDqc9144vP06OJ3pQWfJjHu88W0mu/LfxqzBAg1tx968murFmUi2VAp56VnH3zQgB6FFUweNQGfjX6ECzDGXn6l/QaEEtyh45bz3XjhpCZ6fQZtIVRZ6xJ1WntMVfdtZQDR2wmv6CGR6bP4+9/7MqBI7aw76AK3OHLFa3585W9Uh1mk7AWMJmpeZIm3ar7SDrgS+A6d9/lU5kA8lt18RH5JyUlnpbggY9fSHUIae/sPkemOoS09oG/ziYvaVSHXXbv3t7rsp/Gte7in0+Y4e5DG3O8ZInn9jYjNo39Pu5+vZn1Abq5+7T6ttvFI+lEpJkzbxmjvfH0+d0FjABqk1kZcGfSIhKR9NcCprGPp89vuLsfYmazANx9g5m1TnJcIpLOWkDNL57kV21mmQSna2ZdaBHPbhKR3dUSmr3xJL8/A88BhWZ2E7FZXq5NalQikr68ZYz2xvPc3kfNbAaxaa0MONHdP21gMxFpycJQ8wtGd8uBF+qWufuyZAYmImksDMkP+BfbH2SUA+wNzAcGJTEuEUljoejzc/fBdd8Hs71cnLSIRET2gIRvb3P3mWY2PBnBiEgzEYaan5ldUedtBnAIsGoXq4tISxeW0V6gfZ3XNcT6AJ9JTjgi0iy09JpfcHFze3f/2R6KR0TSnNEyBjx2eW+vmbVy9whwxB6MR0Sagyaaz8/MJpnZWjObU6eswMymmtmC4GfHoNzM7M9mttDMPqn7qA0zOytYf4GZnRXPKdQ3sUHtrC0fmdlkM/uRmZ1cu8SzcxFpgXz7zC4NLXF4iK8/6Owq4HV3LwJeD94DjAWKgmU8cDfEkiVwHTAcGAZcV5sw6xNPn18OsJ7YMztqr/dz4Nk4thWRlqiJBjx28aCzE4jNBQrwN+BN4BdB+cMem4T0fTPrYGbdg3WnunsJgJlNJZZQH6/v2PUlv8JgpHcO25PetpgbPCsRabES6PPrbGbT67y/193vbWCbru6+Oni9BugavO4J1H0o8oqgbFfl9aov+WUC7dgx6dVS8hMJs/gzQHFjZnJ2dzdLzvBKfclvtbtfn4yDikgzlvyHE31pZt3dfXXQrF0blK8EetdZr1dQtpLtzeTa8jcbOkh9Ax7pPQ2riKRMEw547MxkoHbE9izg+TrlZwajvocBpUHzeAow2sw6BgMdo4OyetVX8zt2t0MXkZatiWp+dR90ZmYriI3a3gI8ZWbnAkuB04LVXwLGAQuJzTT1YwB3LzGzG4APg/Wurx38qM8uk188G4tIODXV7W31POjsa5WvYJT3kl3sZxIwKZFjh/a5vSKym5rBA8njoeQnIgkxWsaAgJKfiCRONT8RCaOWMLGBkp+IJE7JT0RCJ0STmYqI7Eg1PxEJI/X5iUg4KfklgbeAzoQkOW/UD1MdQto75dNpDa8UYp+fUt0k+1HNT0TCx2myyUxTSclPRBLSUh5gpOQnIolT8hORMDJv/tlPyU9EEqNZXUQkrNTnJyKhpNvbRCScVPMTkdBp3MOJ0oaSn4gkTslPRMJGFzmLSGhZtPlnPyU/EUmMrvMTkbDSpS4iEk6q+YlIGGnAQ0TCxwFNbCAiYaQ+PxEJHV3nJyLh5K5mr4iEk2p+IhJOSn4iEkaq+YlI+DgQaf7ZT8lPRBLWEmp+GakOQESaodoR34aWBpjZF2Y228w+MrPpQVmBmU01swXBz45BuZnZn81soZl9YmaHNOYUlPxEJGHm8S1xOtrdh7j70OD9VcDr7l4EvB68BxgLFAXLeODuxpyDkp+IJMYTWHbPCcDfgtd/A06sU/6wx7wPdDCz7rt7ECU/EUmIARbxuBags5lNr7OM/8ruHHjVzGbU+ayru68OXq8BugavewLL62y7IijbLRrwEJGEWfx3eBTXac7uzJHuvtLMCoGpZvZZ3Q/d3c2SM7yimp+IJKYJm73uvjL4uRZ4DhgGfFnbnA1+rg1WXwn0rrN5r6Bst4S25nf5jfMZdlQJG0uyuPiE2H9M5/xsMcNHraemOoPVy3O4/ZcD2FLWivb51Vzzp3n0H1zGa8914+6b+qU4+j2jc2EFE66dSYeOW3GMVybvxeSn9932+UmnL+S8S+fy/W+PYVNpNu3aV3HZ1bPo3qOcqqoM7rj5YJYuyUvhGTS98tUZTL8qj63rY/WGvU+roOjMCqo2Gh9ckc+WlRm07Rll+O2ltM53qsuMaVfmUbE6g2iN0f+ccvqevHXb/qo3G1O/U0D3Yys5+FebU3VaCWqae3vNrC2Q4e5lwevRwPXAZOAs4Jbg5/PBJpOBS83sCWA4UFqneZywpNX8zKy3mb1hZvPMbK6ZXZasY+2O157ryq/GH7BD2ax3O3DRCUO55KRvsPKLXE47fxkAVVUZ/P0vfXng1n1SEWrKRCLG/RMHcdGPjmXC+G/ynZOX0LvvJiCWGA8+dC1r1+RuW/+0Hy1g8YJ8Lj37aG678RDGXzY7VaEnjWXC4Cs3M/rFEo5+cgOLH8tl08JM5t/XhsIRVYyZUkLhiCrm39cGgEWP5ZK3bw3H/XMDRz28gU/+rx3Rqu37m/vntnQeWp2is9l9TTTa2xV4x8w+BqYB/3L3V4glvW+Z2QLguOA9wEvAYmAhcB9wcWPOIZnN3hpggrsPBA4DLjGzgUk8XkLmzOhAWWnWDmWz3i0gGjEAPvs4j87dKgGorMhk3sx8qirD1UuwYX0Oiz7vAEBFRRbLv2hPp86xWsv5/zubB+8etEMFoE/fMj6Z0QWAFcva07V7OR06bv3qbpu13MIoHQfVAJDV1mm/b4SKLzNY9e9s+pwQO9c+J2xl1evZsQ0MarYY7lBTbrTOj2JBe2vD3FZUFmdQeETVzg6V3prgOj93X+zuBwXLIHe/KShf7+7HunuRux/n7iVBubv7Je6+r7sPdvfpjTmFpP01u/tqd58ZvC4DPqURIzN72uiT1zD97YJUh5E2CruVs0//UubP68hhR65mfXEuSxbm77DO4oV5HH7UKgD677+Bwq4VdC5sWcmvri0rM9j4aSsKDqqhcn0GuYWxGT5zukSpDJrF+/6ggrLFrXhpZCemnlDAQVdvxjLAo/DJ79sx+Mrm0tStwxMa7U1be6QqY2Z9gYOBD/bE8RrrexcsIxIx3nihMNWhpIWc3Bp+edM07rvjAKIR47QzP+eR+/f72npPP1JE23bV/OXBN/juKYtZtCB/W026panZYrz/k3wOumozWe12/CM3I3Y9CPDlO63J36+GcW+t57hnN/DRje2p3mwsejyXbiOraNOtmU6JnNzr/PaIpA94mFk74BngcnfftJPPxxO7WpucjLbJDqdBx524hmFHreeacw5k229wiGVmRrnmxmm88Wov3n2rB3vts4mu3cuZ+NAbAHTuspU7Jv2HK84fyYaSHP50c+0dR86kp6eyelWb1AWfJNFqeO+yPHp/dys9R8e6RrI7RalYG6v9VazNILsgltSWPpvDgPPLMYN2e0Vo2ytC2eJMSj7KonhGFosfz6Wm3IhWQ6s2zuAJW1J5anFL4FKXtJXU5GdmWcQS36Pu/uzO1nH3e4F7AfJbdUnpN/qNI0s49dwVXHnmgVRuzUxlKGnCuezqWSxf2p5/Phkb4V66OI8ffHfstjUmPf0ql593FJtKs2nbrprKrZnU1GRw/HeXMufjTlSUZ+1q582SO8y4tj15+0Tof3bFtvLux1Sy7PlYolv2fA49joklxdzuEda+35rOQ6vZWmyULcmkbe8Iw27dXg/44rkcNsxp1WwSH6CZnOtjZgY8AHzq7rcl6zi768pbP+XAYaXkdajm4X+/zyMT9+K08cvJyopy0wOxUcr5H+cx8bdFADw49QPatIvQKivKiGOL+eX5g1m+KPU11WQaeGAJx45ZwZKFefzlwVhN729/Hcj097vudP3ee5VxxbUzcYdlS/K445YhezDaPWP9zCyWTc4lr38Nr53UEYBBl29hwHnlfHBFPkv+kUObHlEOu70UgP0vLmf61XlM/X8F4DB4wmayOzbzxOFAM22t12WepAxuZkcCbwOz2f5VXePuL+1qm/xWXXxE3glJiaclsIKOqQ4h7Z3wr2mpDiGt3XzKTJbOKWtUf05+2x5+2MAL4lr31em/mdHAHR4pk7San7u/gzrNRFqmaPOv+oX2Dg8R2U0tpNmr5CciCdNor4iEk5KfiISPHlouImGkp7eJSFipz09EwknJT0RCx4Gokp+IhI4GPEQkrJT8RCR0HIg0/1s8lPxEJEEem4q6mVPyE5HEqdkrIqGj0V4RCS3V/EQklJT8RCR03CESSXUUjabkJyKJU81PREJJyU9Ewsc12isiIeTgushZREJJt7eJSOi469GVIhJSGvAQkTBy1fxEJHw0mamIhJEmNhCRMHLAdXubiISOazJTEQkpV7NXREKpBdT8zNNo1MbM1gFLUx1HHZ2B4lQHkcb0/TQs3b6jvdy9S2N2YGavEDuveBS7+5jGHC9Z0ir5pRszm+7uQ1MdR7rS99MwfUfpKyPVAYiIpIKSn4iEkpJf/e5NdQBpTt9Pw/QdpSn1+YlIKKnmJyKhpOQnIqGk5LcTZjbGzOab2UIzuyrV8aQbM5tkZmvNbE6qY0lHZtbbzN4ws3lmNtfMLkt1TPJ16vP7CjPLBD4HvgWsAD4Evu/u81IaWBoxs5HAZuBhdz8g1fGkGzPrDnR395lm1h6YAZyo36H0oprf1w0DFrr7YnevAp4ATkhxTGnF3d8CSlIdR7py99XuPjN4XQZ8CvRMbVTyVUp+X9cTWF7n/Qr0iyu7ycz6AgcDH6Q4FPkKJT+RJDGzdsAzwOXuvinV8ciOlPy+biXQu877XkGZSNzMLItY4nvU3Z9NdTzydUp+X/chUGRme5tZa+B0YHKKY5JmxMwMeAD41N1vS3U8snNKfl/h7jXApcAUYh3VT7n73NRGlV7M7HHgPWCAma0ws3NTHVOaOQL4EXCMmX0ULONSHZTsSJe6iEgoqeYnIqGk5CcioaTkJyKhpOQnIqGk5CcioaTk14yYWSS4bGKOmT1tZm0asa+HzOzU4PX9ZjawnnVHmdnhu3GML8zsa0/52lX5V9bZnOCxfmNmP0s0RgkvJb/mpcLdhwQzqVQBF9b90Mx26znM7n5eAzOOjAISTn4i6UzJr/l6G+gX1MreNrPJwDwzyzSzW83sQzP7xMwugNhdB2Y2MZin8DWgsHZHZvammQ0NXo8xs5lm9rGZvR7cmH8h8NOg1vlNM+tiZs8Ex/jQzI4Itu1kZq8Gc9jdD1hDJ2Fm/zSzGcE247/y2e1B+etm1iUo29fMXgm2edvM9muSb1NCZ7dqCpJaQQ1vLPBKUHQIcIC7LwkSSKm7H2pm2cB/zexVYjOLDAAGAl2BecCkr+y3C3AfMDLYV4G7l5jZPcBmd/9DsN5jwO3u/o6Z9SF2N8z+wHXAO+5+vZl9G4jnzo9zgmPkAh+a2TPuvh5oC0x395+a2a+DfV9K7IFAF7r7AjMbDtwFHLMbX6OEnJJf85JrZh8Fr98mdv/o4cA0d18SlI8GDqztzwPygSJgJPC4u0eAVWb2753s/zDgrdp9ufuu5uw7DhgYu4UVgLxgBpORwMnBtv8ysw1xnNNPzOyk4HXvINb1QBR4Mih/BHg2OMbhwNN1jp0dxzFEvkbJr3mpcPchdQuCJLClbhHwv+4+5SvrNeW9pRnAYe6+dSexxM3MRhFLpCPcvdzM3gRydrG6B8fd+NXvQGR3qM+v5ZkCXBRMqYSZ9TeztsBbwPeCPsHuwNE72fZ9YKSZ7R1sWxCUlwHt66z3KvC/tW/MbEjw8i3gjKBsLNCxgVjzgQ1B4tuPWM2zVgZQW3s9g1hzehOwxMz+JziGmdlBDRxDZKeU/Fqe+4n158202AOG/kqshv8csCD47GFis7LswN3XAeOJNTE/Znuz8wXgpNoBD+AnwNBgQGUe20edf0ssec4l1vxd1kCsrwCtzOxT4BZiybfWFmBYcA7HANcH5T8Azg3im4seMSC7SbO6iEgoqeYnIqGk5CcioaTkJyKhpOQnIqGk5CcioaTkJyKhpOQnIqH0/wGM/4MrOqNORgAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "y_pred = clf1.predict(X_test)\n",
    "ConfusionMatrixDisplay.from_predictions(y_test, y_pred)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.97      0.94      2535\n",
      "           1       0.90      0.94      0.92      2511\n",
      "           2       0.97      0.85      0.90      2454\n",
      "\n",
      "    accuracy                           0.92      7500\n",
      "   macro avg       0.93      0.92      0.92      7500\n",
      "weighted avg       0.92      0.92      0.92      7500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Incremental Approach [using partial_fit()]**\n",
    "\n",
    "We will now assume that the data can't be kept completely in the main memory and hence, will load chunks of data and fit usng `partial_fit()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-2.29159844,  0.02091326,  0.83692475,  0.40334635, -0.85712345,\n",
       "         0.10922827,  0.12431572,  2.28815044,  0.08941231,  1.3970629 ],\n",
       "       [ 0.92861135,  0.70557977,  0.04412851,  0.72054533,  0.09660703,\n",
       "         0.30020664,  2.11156696, -1.11936906, -0.44856979,  0.01935755],\n",
       "       [-0.19039778, -0.45235961, -0.64982729,  0.34137055, -0.34691607,\n",
       "         0.21451974, -0.44904781,  0.55076812,  0.78134819,  0.33105366],\n",
       "       [ 1.1583492 ,  0.49090667,  1.06375715, -0.51689404,  1.1209298 ,\n",
       "        -0.27734821,  0.64698903, -1.90202329, -1.64475696, -0.78198161],\n",
       "       [ 0.97511431, -0.58098048,  0.21484446, -0.07367407,  1.17026029,\n",
       "         0.09359779,  0.77655646, -1.25990625, -0.65231873,  0.17549224]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 1, 0, 1, 1])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to load data chunk, we will first store the given (training) data in a CSV file.\n",
    "\n",
    "This is just for demonstration purpose. In a real-case scenario, the large dataset might already be in the form of say, a CSV file which we will be reading in multiple iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-2.29159844,  0.02091326,  0.83692475,  0.40334635, -0.85712345,\n",
       "         0.10922827,  0.12431572,  2.28815044,  0.08941231,  1.3970629 ,\n",
       "         2.        ],\n",
       "       [ 0.92861135,  0.70557977,  0.04412851,  0.72054533,  0.09660703,\n",
       "         0.30020664,  2.11156696, -1.11936906, -0.44856979,  0.01935755,\n",
       "         1.        ],\n",
       "       [-0.19039778, -0.45235961, -0.64982729,  0.34137055, -0.34691607,\n",
       "         0.21451974, -0.44904781,  0.55076812,  0.78134819,  0.33105366,\n",
       "         0.        ],\n",
       "       [ 1.1583492 ,  0.49090667,  1.06375715, -0.51689404,  1.1209298 ,\n",
       "        -0.27734821,  0.64698903, -1.90202329, -1.64475696, -0.78198161,\n",
       "         1.        ],\n",
       "       [ 0.97511431, -0.58098048,  0.21484446, -0.07367407,  1.17026029,\n",
       "         0.09359779,  0.77655646, -1.25990625, -0.65231873,  0.17549224,\n",
       "         1.        ]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = np.concatenate((X_train, y_train[:,np.newaxis]), axis=1)\n",
    "train_data[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.asarray(train_data) \n",
    "np.savetxt('train_data.csv',a, delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, our data for demonstration is ready in a csv file.\n",
    "\n",
    "Let's create `SGDClassifier` object that we intend to train with `partial_fit()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf2 = SGDClassifier(max_iter=1000, tol=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Processing data chunk by chunk**\n",
    "\n",
    "* Pandas' read_csv() function has an attribute `chunksize` that can be used to read data chunk by chunk. \n",
    "\n",
    "* The `chunksize` parameter specifies the number of rows per chunk. (The last chunk may contain fewer than chunksize rows, of course.) \n",
    "\n",
    "* We can then use this data for `partial_fit()`. \n",
    "\n",
    "* We can then repeat these two steps multiple times. That way entire data may not be required to be kept in memmory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After iter # :  1\n",
      "[[ 19.38830885  -9.8407469  -45.97717728  -5.87280243   0.42674605\n",
      "    6.21765462   3.55850528   0.1417346   41.08967472 -13.94867119]\n",
      " [ 12.92169609  15.81072392  18.0450216   -9.00425388  12.78754988\n",
      "   18.86647869   9.1221019  -24.31521829 -24.99480569 -14.25634197]\n",
      " [-29.47922706   8.40986526  24.23256001  13.41447864   1.94339806\n",
      "   -3.96856641  -2.62356224  22.68345616 -13.33739481  14.6376807 ]]\n",
      "\n",
      "[-59.03986614 -74.98556842  -6.04887573]\n",
      "------------------------------\n",
      "After iter # :  2\n",
      "[[ -0.43318992  -1.0332125  -33.40136516   0.25054696   3.98749852\n",
      "   -1.00136424   2.54789093  17.25781737  36.12161057   2.72497412]\n",
      " [ 22.4240924    1.12713107   2.65918168   3.41619314   2.26348056\n",
      "   10.95051098 -12.5037477  -27.82945064 -12.54647862  12.96506279]\n",
      " [-18.262215    -1.03959563  15.93677646  -5.23414935   8.99892245\n",
      "    3.27627136   4.47310495  13.58859847  -9.25742246   0.18387247]]\n",
      "\n",
      "[-50.34539254 -50.4647003   -4.39114887]\n",
      "------------------------------\n",
      "After iter # :  3\n",
      "[[  1.59753532   0.34706688 -21.75556115   0.96276257  -0.31501835\n",
      "    1.98008086   1.60594408   9.01962823  22.71546625   1.25182019]\n",
      " [ 20.63431088  -8.23821557   6.28481279   6.59239713   1.29684542\n",
      "    8.12150785  -0.89386001 -27.53237941 -15.67401586   0.51485952]\n",
      " [ -7.25862109  -1.04801571   8.00963145   4.54380002  -0.0818056\n",
      "   -7.61300846  -5.35724345   4.56109616  -5.48186436   0.67083948]]\n",
      "\n",
      "[-23.06547087 -36.41730191  -4.36901345]\n",
      "------------------------------\n",
      "After iter # :  4\n",
      "[[  4.12979806  -3.25754191 -17.44502475  -0.50180349   4.72890367\n",
      "    0.26726567  -0.8340666    3.86640099  16.98426266  -0.63411815]\n",
      " [  6.35059183  -4.84304363   1.29398638  -4.2035575   -4.03819594\n",
      "   -3.40641356 -10.33899167  -8.15259174  -4.13512923  -1.69966893]\n",
      " [ -7.60896558  -0.62568421   7.60573801  -4.1237475   -3.96908967\n",
      "   -7.54492315   4.45514816   5.17755662  -4.8960158    3.82540408]]\n",
      "\n",
      "[-27.31709493 -36.20669914   4.08371098]\n",
      "------------------------------\n",
      "After iter # :  5\n",
      "[[  0.78636273   0.88430578 -13.90820641   2.41506199   2.04141795\n",
      "   -4.00897905  -4.62919637   6.04379268  14.62334255  -2.23188323]\n",
      " [ 11.64286411   5.07689199   4.43427592  -2.12207189  -1.29634325\n",
      "    0.31799044  -0.6742446  -15.98032997  -9.79946464   4.4346227 ]\n",
      " [ -8.63695637   2.60007172   7.98740706  -4.27058413   1.92929935\n",
      "    0.43010927  -4.71942397   6.20087622  -4.86261087  -1.06754917]]\n",
      "\n",
      "[-20.19527231 -21.26607071   2.9874717 ]\n",
      "------------------------------\n",
      "After iter # :  6\n",
      "[[ 5.66763313e+00  2.18980763e+00 -1.40673290e+01  2.14111227e+00\n",
      "   4.74504070e+00 -1.53960803e+00  1.80866526e+00  3.55872027e-01\n",
      "   1.26861684e+01  2.10331381e+00]\n",
      " [ 2.69700626e+00 -6.98074825e-03  1.74210040e+00 -1.07587636e+00\n",
      "  -3.18587477e+00  3.95901745e+00  7.45153546e+00 -4.06018805e+00\n",
      "  -3.03913665e+00  2.59978972e+00]\n",
      " [-7.56359601e+00  1.74320666e+00  4.32950198e+00  8.80019215e-01\n",
      "   3.55218798e+00  5.25153111e+00 -6.85714986e-01  6.76650729e+00\n",
      "  -1.39090861e+00  1.14249253e+00]]\n",
      "\n",
      "[-16.91491035 -19.89733634  -4.87166076]\n",
      "------------------------------\n",
      "After iter # :  7\n",
      "[[  2.17487785   1.61152085 -12.9117516    1.00578869  -1.12701292\n",
      "   -0.21537709  -0.25258184   3.90354829  12.95157665  -4.31652165]\n",
      " [  9.27413961   7.55853696   1.60543694  -4.14975418   0.27643622\n",
      "    0.10506277  -1.49716021 -11.76319642  -5.73296644   2.89124642]\n",
      " [ -6.50848168  -3.24427134   4.66122605   3.19002412   1.99994282\n",
      "    3.96090081   0.53941647   5.35347496  -2.20352539   4.16345605]]\n",
      "\n",
      "[-16.77205487 -19.83694959  -3.27313782]\n",
      "------------------------------\n",
      "After iter # :  8\n",
      "[[  1.14023291  -0.14622242  -9.07827058  -3.47535      0.51534122\n",
      "    0.23476031  -0.3641228    3.20414518   9.27426056   2.60493271]\n",
      " [  8.45627242   1.67487973   2.58713351   0.80371066  -2.25326848\n",
      "   -4.6416978   -3.85497924 -11.28898552  -6.43585329  -0.79821464]\n",
      " [ -6.44012417  -0.54232307   4.41593144   3.43927972   1.44664993\n",
      "    0.81713453   2.65367474   5.39568371  -1.96915341   4.05105577]]\n",
      "\n",
      "[-10.91632851 -19.98054603   0.175747  ]\n",
      "------------------------------\n",
      "After iter # :  9\n",
      "[[ 2.93286530e+00 -2.07431528e+00 -1.02058901e+01  2.24896060e+00\n",
      "   1.44864272e+00  4.77360353e-01  2.41001411e+00  1.65131331e+00\n",
      "   9.71310726e+00  1.49158994e+00]\n",
      " [ 5.59776041e+00  2.76891146e+00  3.98802124e+00 -2.44307752e+00\n",
      "  -1.76966142e+00  1.21873812e+00  1.79062306e+00 -8.61371733e+00\n",
      "  -6.70830787e+00  2.02885834e+00]\n",
      " [-6.15177247e+00  1.28721872e+00  4.80675563e+00 -1.64093148e+00\n",
      "  -4.06449104e+00 -5.45789417e-01 -1.87251820e-03  4.85902612e+00\n",
      "  -2.51416506e+00 -5.10965604e-02]]\n",
      "\n",
      "[ -9.94175275 -15.9018863   -6.03259008]\n",
      "------------------------------\n",
      "After iter # :  10\n",
      "[[ 0.57372779  0.93741165 -9.16639127 -1.61574541 -0.65766851 -1.37974049\n",
      "   1.43400391  3.9177061   9.61375451  0.05674784]\n",
      " [ 2.28534626  0.75683994  1.82925278 -0.33898239 -1.63492281  0.67328324\n",
      "   2.65288817 -3.6174659  -2.95509053  0.07243071]\n",
      " [-4.93984874 -1.39276341  4.93458103 -1.69042452  0.48208759  1.20213882\n",
      "  -1.41807146  3.3629339  -3.17515023  0.92392828]]\n",
      "\n",
      "[-13.76666229 -14.85896444  -2.88815854]\n",
      "------------------------------\n",
      "After iter # :  11\n",
      "[[ 2.73435194e+00  7.23603594e-01 -7.76006535e+00 -1.74722570e+00\n",
      "   1.12191799e-01 -1.01200484e+00  9.90759858e-01  6.59648304e-01\n",
      "   7.16753651e+00  3.80164889e-01]\n",
      " [ 4.94221697e+00  2.87566315e+00 -5.24459792e-01 -1.01263509e+00\n",
      "   8.74237195e-01 -2.96585792e+00 -1.95263343e+00 -5.57677114e+00\n",
      "  -1.57045467e+00  1.89240235e+00]\n",
      " [-4.80436057e+00  3.60709686e-01  1.93591953e+00  1.81524724e-01\n",
      "   7.71107544e-03  2.24745694e-01  1.18819771e+00  4.70623711e+00\n",
      "  -7.59350644e-03  5.07124385e-01]]\n",
      "\n",
      "[ -9.33088242 -13.01378207  -0.22690318]\n",
      "------------------------------\n",
      "After iter # :  12\n",
      "[[ 3.78681810e-01  5.57617906e-01 -8.70974445e+00  9.03660828e-01\n",
      "   7.51327096e-01 -2.87259473e-01  1.29949349e+00  3.91922954e+00\n",
      "   9.20672200e+00 -1.03173476e+00]\n",
      " [ 4.81903951e+00  1.60775740e+00  1.11979888e+00 -6.67261996e-03\n",
      "  -2.62019976e-01 -1.07866815e+00  1.51464407e+00 -6.25558322e+00\n",
      "  -3.28620887e+00 -1.25183691e+00]\n",
      " [-4.03897358e+00  2.46263347e+00  2.44603366e+00 -5.79289132e-01\n",
      "  -2.26814236e+00  9.92631830e-01 -8.97331013e-01  3.54610907e+00\n",
      "  -8.86987559e-01  4.55196466e-01]]\n",
      "\n",
      "[ -7.77521691 -12.18083387   1.23535232]\n",
      "------------------------------\n",
      "After iter # :  13\n",
      "[[-0.25713377 -0.34849415 -6.50014505  1.12048002 -0.73089061 -0.61008638\n",
      "   0.86796394  3.56271273  7.1041755   2.73770579]\n",
      " [ 5.25976768 -2.13089839 -1.4790284   0.44365129 -0.90931694 -3.67277652\n",
      "   1.34161944 -5.47341001 -0.68065171  3.06042055]\n",
      " [-4.37953216 -0.63439005  0.71961305 -2.20809493 -2.07378852 -0.18773528\n",
      "   0.74492294  4.81406291  1.11746096  0.51822926]]\n",
      "\n",
      "[ -7.76865653 -11.5314022   -2.52483825]\n",
      "------------------------------\n",
      "After iter # :  14\n",
      "[[ 2.35735501  0.93807411 -7.43945079 -0.33451531  0.4441513   0.8141498\n",
      "  -1.74114398  0.9443651   6.98544283 -2.02510503]\n",
      " [ 6.18867665  1.99135734 -0.64957144  1.13057564  1.40527425  1.45347398\n",
      "  -0.50606953 -6.98685955 -1.9742373   1.09371231]\n",
      " [-3.60844935  1.37636163  4.48261476  0.92595525 -0.82584851  1.0150513\n",
      "   0.90348273  2.01635132 -3.26397775  3.01084848]]\n",
      "\n",
      "[ -9.10972811 -10.84377116  -2.48626009]\n",
      "------------------------------\n",
      "After iter # :  15\n",
      "[[ 1.06077704 -0.4824955  -6.20970444 -0.65295966  0.30158007 -1.46517846\n",
      "  -0.87514798  1.85985838  6.22246354 -0.84813864]\n",
      " [ 3.57101878 -1.62141009 -0.34293639  1.38147117  0.49891704 -1.08968341\n",
      "   1.76769088 -4.04757435 -1.17348378  1.70347244]\n",
      " [-3.78622137 -0.34127612  3.40356446 -0.9659685  -0.06276722 -0.9929648\n",
      "  -1.66025569  2.76739423 -2.026308    1.74795668]]\n",
      "\n",
      "[-8.47543764 -9.53346309 -0.49596288]\n",
      "------------------------------\n",
      "After iter # :  16\n",
      "[[ 1.82999217  0.3347636  -5.62263861  1.86627297  0.46268445  0.31758735\n",
      "   1.52459493  0.65662685  5.25862834 -1.04092488]\n",
      " [ 2.46667622 -0.48919705  1.54090436 -2.84172815  0.12144922  0.40509839\n",
      "   0.7391874  -3.68715986 -2.7231957  -2.07704629]\n",
      " [-2.54390768  0.8805303   1.24090928  0.98390018  0.10365998 -0.75904713\n",
      "   0.22988936  2.38373855 -0.23623034 -1.10262744]]\n",
      "\n",
      "[ -6.64884129 -10.0865789   -2.28103332]\n",
      "------------------------------\n",
      "After iter # :  17\n",
      "[[ 1.46705568 -0.43044773 -6.53094655 -1.61429038 -0.46180992 -0.15086572\n",
      "   1.18380237  1.54085701  6.39258473 -0.1236393 ]\n",
      " [ 4.3649165   0.14131389  0.19569618  2.79227305 -1.07541552  0.97130011\n",
      "   2.12299893 -5.25568849 -2.09587372 -1.80410508]\n",
      " [-2.90230291  0.16399623  1.52934326 -0.3973443   0.00724875  0.88846686\n",
      "   0.98637696  2.66260952 -0.39173751  0.89463231]]\n",
      "\n",
      "[ -5.55472948 -10.0477626   -1.10933749]\n",
      "------------------------------\n",
      "After iter # :  18\n",
      "[[ 1.21862863  0.31714157 -6.22946405 -0.52386686  1.25436158 -1.06767475\n",
      "  -0.33907433  1.68324789  6.17554095  1.00159607]\n",
      " [ 4.77917631  0.31649481 -1.15834116  0.66254816  0.30812263 -0.1647079\n",
      "   0.55064288 -5.06632272 -0.81807808 -1.57668388]\n",
      " [-4.84840044 -1.24476567  2.94979109  0.83806006 -0.59294345  0.23116222\n",
      "  -0.46847019  4.24996435 -1.07933431 -0.11644074]]\n",
      "\n",
      "[-6.11977811 -6.83726017 -1.62104969]\n",
      "------------------------------\n",
      "After iter # :  19\n",
      "[[ 2.784369   -1.873803   -3.69274005  0.76415092  0.63458938  0.76506103\n",
      "   1.01698213 -1.43862802  2.77014405  1.26311436]\n",
      " [ 2.78496594  1.94027272  1.46831492  1.94494511 -0.12680849 -1.45075119\n",
      "   0.71024127 -4.02685713 -2.78257983 -0.72025156]\n",
      " [-1.99480305  0.93257698  1.87046091  0.03770753 -1.36926451  1.71600148\n",
      "  -0.95204163  1.41928857 -1.15070124  0.64041802]]\n",
      "\n",
      "[-5.66156085 -7.41107514 -1.0517265 ]\n",
      "------------------------------\n",
      "After iter # :  20\n",
      "[[-0.03059445  0.86407141 -4.85807046  0.35936911 -0.11911422 -0.10142259\n",
      "  -0.25952976  2.47177112  5.23971803  0.55508446]\n",
      " [ 1.72889379  1.93894267  2.50128294 -0.55339075  0.0977128   1.38042046\n",
      "  -0.45334133 -3.29688904 -3.4377388   0.03354658]\n",
      " [-1.97924552 -1.00690739  1.68642956  1.17106647  0.99423369  1.54033551\n",
      "  -0.68169762  1.49317098 -0.95943282  0.05786417]]\n",
      "\n",
      "[-5.17182715 -7.86027965  0.37124357]\n",
      "------------------------------\n",
      "After iter # :  21\n",
      "[[ 0.7728425  -0.43586889 -4.53441023 -0.18361908 -0.61697345  0.58516672\n",
      "   1.26988598  1.36016303  4.54448352  0.91045153]\n",
      " [ 2.15423834  1.47981503  0.09229772  1.429837   -0.52087136  2.08881383\n",
      "  -0.2361131  -2.59171695 -1.02977654  1.01969971]\n",
      " [-3.39171174  0.1913217   3.39047495 -2.24374402 -0.50842973  0.26846219\n",
      "  -0.60162806  2.30780507 -2.18262613 -0.21189566]]\n",
      "\n",
      "[-6.10692559 -8.30144723 -0.54473056]\n",
      "------------------------------\n",
      "After iter # :  22\n",
      "[[ 0.74381059 -0.42628646 -4.20577162  0.63131011  0.40781215  0.74975744\n",
      "  -1.3298004   1.22970227  4.20346091 -0.53435548]\n",
      " [ 1.8120276   2.07627232  1.77142705 -0.96922296  1.95115375  2.16369166\n",
      "   1.18561041 -3.02920243 -2.68843905  0.37548719]\n",
      " [-3.24357985 -0.84565716  1.05636135  0.26558079 -0.66520459  0.48455805\n",
      "  -0.88380571  3.30299368  0.2645226   0.36252403]]\n",
      "\n",
      "[-5.19636759 -8.73209711 -0.54985918]\n",
      "------------------------------\n",
      "After iter # :  23\n",
      "[[ 3.27342103e-01 -3.55222358e-02 -4.24854785e+00  3.44489789e-01\n",
      "   1.54444216e+00 -7.67596825e-01 -3.26671554e-01  1.74324656e+00\n",
      "   4.42936627e+00 -9.88560474e-01]\n",
      " [ 4.57389040e+00 -4.08345992e-03  9.29902774e-01 -2.64519583e-01\n",
      "   3.06510764e-01 -1.14385674e-01  4.84378381e-02 -5.87071014e+00\n",
      "  -2.97602405e+00 -2.16380277e+00]\n",
      " [-3.28802719e+00  1.16979694e-01  1.76780372e+00  2.13646001e+00\n",
      "  -2.98809406e-01  8.95312678e-02  1.00472613e+00  2.99882694e+00\n",
      "  -4.81676977e-01 -2.27046727e-01]]\n",
      "\n",
      "[-6.87079669 -8.72011384 -0.98900169]\n",
      "------------------------------\n",
      "After iter # :  24\n",
      "[[ 0.39806814  0.85392451 -5.55986146  0.05746278 -0.76804008 -0.50510214\n",
      "  -1.57469542  2.31711125  5.8095804  -0.17002208]\n",
      " [ 3.62964579 -1.89952253  1.09362719 -1.5207439  -0.94971449 -0.0800531\n",
      "   0.36536751 -4.83707706 -2.74431814  1.69570542]\n",
      " [-1.66684561 -1.79249105  1.28449738 -0.93069556 -0.77657718 -0.69545845\n",
      "  -1.17235882  1.32555093 -0.66195309  0.95791629]]\n",
      "\n",
      "[-5.65276015 -6.68920397 -1.79135941]\n",
      "------------------------------\n",
      "After iter # :  25\n",
      "[[-0.01898631 -0.72969548 -3.86687668 -1.42871687 -0.67766877  0.9272515\n",
      "   0.63335385  1.96111443  4.16833885 -0.85791643]\n",
      " [ 3.95061278 -1.1250714   0.39830802 -0.35450217  0.87850044  1.26983184\n",
      "   0.45945413 -4.86772876 -2.13490152 -1.01012395]\n",
      " [-3.16063309 -0.27779233  2.12719495  0.38578092  0.3217026   1.0817817\n",
      "   0.20523476  2.66811557 -0.92334947  0.01881088]]\n",
      "\n",
      "[-4.87261211 -6.72687172 -1.75744583]\n",
      "------------------------------\n",
      "After iter # :  26\n",
      "[[-0.49453747 -1.12060109 -3.56430278 -0.16584365  0.79873991  1.85781206\n",
      "   1.50190239  2.37132744  4.0482225  -0.44712405]\n",
      " [ 1.7827346  -0.22894652  0.61659238  0.0063293  -0.68016705 -0.5803449\n",
      "  -0.60202422 -2.41560706 -1.43336996 -0.24508131]\n",
      " [-1.46330646  0.5329374   0.74191478 -0.11448193  0.35678164 -0.53156063\n",
      "  -0.85978302  1.35707636 -0.16613594 -1.07063408]]\n",
      "\n",
      "[-4.10603797 -8.22165655 -1.71113513]\n",
      "------------------------------\n",
      "After iter # :  27\n",
      "[[ 1.68977401  0.0635014  -4.30500649 -0.92223439  1.21465001  0.14966909\n",
      "  -0.48803139  0.16170606  3.9016322  -0.14029386]\n",
      " [ 2.76113804  0.33993281  0.65040026  0.77709493 -0.54229342  0.5663105\n",
      "   0.56747699 -3.58863604 -1.89234308  1.42098246]\n",
      " [-2.87272069  0.17333331  2.00819543 -0.69941743 -0.12918147 -0.47239089\n",
      "  -1.00592435  2.38758003 -0.91968295 -0.52783472]]\n",
      "\n",
      "[-4.85170994 -7.46394203 -1.66979769]\n",
      "------------------------------\n",
      "After iter # :  28\n",
      "[[ 0.3252395   1.10676098 -4.66678035 -0.31470563  0.7395233  -0.03609679\n",
      "  -0.1941685   1.95541419  4.88022543  1.19603552]\n",
      " [ 1.42934304 -0.21339803  0.61547082  0.83135241  0.34591937  0.39720566\n",
      "   0.09184825 -1.99747812 -1.27952311  0.43301674]\n",
      " [-2.60051406 -0.98002904  2.88041952 -0.19416701 -0.2450842   0.44202831\n",
      "  -0.46486949  1.62864689 -1.97563002  0.72243713]]\n",
      "\n",
      "[-5.19745504 -6.0487155  -1.64002716]\n",
      "------------------------------\n",
      "After iter # :  29\n",
      "[[ 0.25213266 -0.45700128 -4.01246453  0.09800696  0.42587866  0.6695858\n",
      "  -0.58157301  1.71375216  4.20786372 -0.56478902]\n",
      " [ 0.91870629 -1.0434746   1.86110342  0.75918241 -0.34278594 -0.68595775\n",
      "   0.32838926 -2.0186158  -2.39906462  0.77291631]\n",
      " [-2.47978482 -0.51500671  1.05300169 -1.83225913  0.88333652 -0.08844914\n",
      "  -0.22786206  2.40217965 -0.06176851 -0.02655215]]\n",
      "\n",
      "[-3.51835688 -7.7229954  -0.61194507]\n",
      "------------------------------\n",
      "After iter # :  30\n",
      "[[ 0.88823496  0.58998191 -3.95023484 -0.92917463 -0.44138137  0.23917043\n",
      "   0.42344633  0.93093598  3.86616324  0.54647142]\n",
      " [ 2.10271793 -1.07867461  1.67201792 -0.47079813 -0.79414212  0.15519045\n",
      "  -1.25860005 -3.32284212 -2.70704852 -0.04625841]\n",
      " [-2.68678904  0.4966921   2.2942838   0.22974526 -0.71332267  0.32719828\n",
      "  -0.57640357  2.02445162 -1.30777744 -1.41152609]]\n",
      "\n",
      "[-5.15728266 -6.41452556  0.35900203]\n",
      "------------------------------\n",
      "After iter # :  31\n",
      "[[ 0.63660633  0.28917067 -3.66070923 -0.51790163 -0.58533978  0.36584792\n",
      "   1.20062139  1.08310449  3.66336602 -0.90257807]\n",
      " [ 3.04040502 -1.18837977  1.49528073 -0.94410081 -1.00886039 -0.34348118\n",
      "  -0.91236688 -4.3422028  -2.92192238 -0.17465557]\n",
      " [-1.13406994 -0.76640528  1.53280497  0.62050653 -1.20092115  0.38426153\n",
      "  -0.37180569  0.57153404 -1.15921368  1.31902994]]\n",
      "\n",
      "[-3.86475706 -6.41236979 -0.30510748]\n",
      "------------------------------\n",
      "After iter # :  32\n",
      "[[ 0.70468953 -0.18013638 -3.82221085  0.65383186 -0.59045243 -0.01348844\n",
      "  -0.60536896  1.08362729  3.80770867 -0.29910315]\n",
      " [ 1.46177397 -1.83974591  1.23356257 -1.24154523  1.04129119 -1.57986043\n",
      "   0.10947387 -2.34568219 -1.95849841  0.45289094]\n",
      " [-2.39095714  0.16110161  1.54135367  0.3224621  -0.54460738 -0.27706659\n",
      "   0.6692095   2.05238307 -0.62552409 -0.02322233]]\n",
      "\n",
      "[-4.17600948 -4.8824403  -0.9025227 ]\n",
      "------------------------------\n",
      "After iter # :  33\n",
      "[[ 7.82272570e-01  5.23147186e-01 -3.89137433e+00  4.94805677e-04\n",
      "   4.09167928e-01 -1.02848471e+00 -8.16618269e-01  1.02663084e+00\n",
      "   3.84860706e+00  4.56647498e-01]\n",
      " [ 2.33067149e+00  2.39814711e-01  5.12924208e-01  4.66101360e-01\n",
      "  -1.50366589e-01 -1.17816108e-01  1.19883486e+00 -3.01107339e+00\n",
      "  -1.55850974e+00  2.21131603e-01]\n",
      " [-2.68290052e+00  1.87650948e-01  2.86336955e+00  4.36484818e-02\n",
      "   2.73733719e-01  5.83377509e-01  1.31142534e+00  1.73454263e+00\n",
      "  -1.92170185e+00  3.88470585e-01]]\n",
      "\n",
      "[-4.1821583  -5.18693224  0.57312601]\n",
      "------------------------------\n",
      "After iter # :  34\n",
      "[[ 0.3193092  -0.84690198 -4.12356883 -0.61808053 -0.10145616  0.80843924\n",
      "   0.16697511  1.69007929  4.29837857  0.42297458]\n",
      " [ 1.03951633 -0.87117232  0.88142002 -0.72727718  0.14014869  1.48433628\n",
      "  -0.80533368 -1.67019491 -1.39726408 -0.68737935]\n",
      " [-1.88339133  0.40802511  1.89111119  0.11702363  0.00740045 -0.07867069\n",
      "   1.43890395  1.27729162 -1.22103962 -1.018166  ]]\n",
      "\n",
      "[-4.77290014 -4.59734854 -1.74278925]\n",
      "------------------------------\n",
      "After iter # :  35\n",
      "[[ 0.88524704  0.70333668 -3.76599931 -0.2618525  -0.26973672  0.21714959\n",
      "   0.2121653   0.84209899  3.66924598  0.33314392]\n",
      " [ 2.59859045  0.30231678 -0.28511431 -0.53671784  0.25517139  0.93208761\n",
      "   0.41588584 -2.92754473 -0.81567059 -0.50501041]\n",
      " [-2.53044522  0.20548351  2.1379417   0.1351346   1.29687571 -0.50314697\n",
      "   0.01882263  1.91809912 -1.20710796  0.16925897]]\n",
      "\n",
      "[-3.65777416 -4.05282439 -1.15405047]\n",
      "------------------------------\n",
      "After iter # :  36\n",
      "[[ 0.53385971 -0.25391035 -3.44099113  1.02438303  0.25760136  0.0478077\n",
      "   0.51394436  1.09435275  3.47136393  0.4243917 ]\n",
      " [ 1.93047718 -0.42106239  0.0677711   0.86224896 -1.23204776  1.45943301\n",
      "   0.26911793 -2.31502473 -0.9067408  -0.75457853]\n",
      " [-2.57747611  0.1415482   1.90806619 -0.44671718 -0.0259697  -0.53468792\n",
      "  -0.18452661  2.08892007 -0.93948481 -0.15185867]]\n",
      "\n",
      "[-3.92992725 -5.17277079 -0.8728966 ]\n",
      "------------------------------\n",
      "After iter # :  37\n",
      "[[ 0.31893541 -0.48141868 -3.16201247 -0.31268324  0.6363704  -0.62617696\n",
      "  -0.5733622   1.20843929  3.26405984 -0.61242716]\n",
      " [ 2.34281476  0.68970333  0.50750441  0.14112554  0.24575617  0.17106287\n",
      "  -0.15991825 -3.0227046  -1.55792395 -0.06044275]\n",
      " [-2.39598826  0.39953089  1.66237814  0.19781938  0.076624    0.71237008\n",
      "  -0.59922338  1.99765154 -0.75355389  0.46688605]]\n",
      "\n",
      "[-3.92014745 -5.43797461 -0.33918915]\n",
      "------------------------------\n",
      "After iter # :  38\n",
      "[[-0.44300853 -0.42550613 -2.26870103 -0.97907595 -1.10539163  0.07429812\n",
      "   0.78944695  1.66088379  2.63210629  0.53091899]\n",
      " [ 1.93338636  2.18712907  0.84329312 -0.15833699  0.03897163 -0.78794512\n",
      "  -0.75093642 -2.70727452 -1.74233447 -0.13940723]\n",
      " [-1.98471869 -0.29123466  1.3088534   0.80128045 -0.35543808  0.25502799\n",
      "   0.31643563  1.68893799 -0.5508575  -0.33142502]]\n",
      "\n",
      "[-3.66193757 -4.65957632 -0.86106907]\n",
      "------------------------------\n",
      "After iter # :  39\n",
      "[[ 0.69916704  0.2648374  -3.23394675  0.32070175  0.30463575 -0.6625447\n",
      "   0.15163659  0.79522315  3.17721633 -0.28347378]\n",
      " [ 2.75061563  0.83624566  0.07368349 -0.04356039  0.90927952  0.19919471\n",
      "  -0.9076899  -3.28706261 -1.26734355 -0.210637  ]\n",
      " [-2.74866648  0.47131731  2.19838226  0.02007493  0.41354545 -0.43635768\n",
      "   0.3014896   2.14564664 -1.17787609  0.27210047]]\n",
      "\n",
      "[-3.65738754 -5.67694427 -0.10235796]\n",
      "------------------------------\n",
      "After iter # :  40\n",
      "[[ 0.96155122  0.25787336 -3.33402044 -0.31180206 -0.8111628   0.22035598\n",
      "  -0.84781411  0.53536312  3.17154808  0.13570611]\n",
      " [ 2.25457292  0.75691682  0.0443828  -0.29228003 -0.1389528  -0.59253009\n",
      "   0.10933489 -2.68624965 -1.02156525  0.27695456]\n",
      " [-2.00303289  0.03647635  1.84549261 -0.25951983 -0.6498331  -0.60163552\n",
      "   0.39617441  1.44153093 -1.12028465  0.83394805]]\n",
      "\n",
      "[-2.68138419 -5.42020786 -1.09001914]\n",
      "------------------------------\n",
      "After iter # :  41\n",
      "[[ 0.14149982 -0.1552038  -2.89724062 -0.2432251  -0.21596779 -0.24269318\n",
      "  -0.14624722  1.28535193  3.05584754 -0.04200232]\n",
      " [ 2.42170837 -0.42887075  0.41925954 -0.29120259 -0.41141005 -0.23733535\n",
      "  -0.44506788 -3.07168305 -1.49706312 -0.95317384]\n",
      " [-1.99616888  0.09973646  1.68604687  0.32741788  0.84281616  0.09084677\n",
      "   0.77562158  1.51335945 -0.95171141 -0.13840053]]\n",
      "\n",
      "[-4.1318807  -4.94913487  0.35983073]\n",
      "------------------------------\n",
      "After iter # :  42\n",
      "[[ 0.55598958  0.3955398  -3.2754199  -0.44788468  1.22052456 -0.07422355\n",
      "  -0.69754166  0.98519409  3.28367735 -0.27059053]\n",
      " [ 2.17939075  1.08586237  1.07817203  0.72763327  0.61529484  0.42342922\n",
      "   0.35105907 -3.11571058 -2.10128299 -0.83555629]\n",
      " [-2.20475771 -0.05232692  1.49252946 -0.02338595 -0.09721158  0.14752137\n",
      "   1.28456057  1.85684855 -0.6534221  -0.36964453]]\n",
      "\n",
      "[-4.59009077 -5.42431084 -1.29315445]\n",
      "------------------------------\n",
      "After iter # :  43\n",
      "[[-0.26312665  0.18591379 -3.03535684  0.19791077  0.02474518 -0.16581435\n",
      "   0.06587531  1.83270296  3.37920849 -0.02031577]\n",
      " [ 1.59309509 -1.24224505  0.49024796  0.7850702   1.15118016  0.12128868\n",
      "  -0.39254078 -2.12818598 -1.21553276 -0.81486961]\n",
      " [-2.33096267 -0.36798865  2.076906   -0.25360239 -1.22425305  0.6667789\n",
      "  -0.52529515  1.71299159 -1.22760574  0.28226229]]\n",
      "\n",
      "[-3.42973886 -4.96024596 -1.05993316]\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "chunksize = 1000 \n",
    "iter = 1 \n",
    "\n",
    "for train_df in pd.read_csv('train_data.csv', chunksize=chunksize, iterator=True):\n",
    "    # print(train_data.shape)\n",
    "    if iter ==1:\n",
    "        # print(train_df)\n",
    "        # In the first iteration, we are specifying all possible class labels.\n",
    "        X_train_partial = train_df.iloc[:,0:10]\n",
    "        y_train_partial = train_df.iloc[:,10]\n",
    "\n",
    "        clf2.partial_fit(X_train_partial,y_train_partial,\n",
    "                        classes=np.array([0,1,2])) \n",
    "    \n",
    "    else:\n",
    "        X_train_partial = train_df.iloc[:,0:10]\n",
    "        y_train_partial = train_df.iloc[:,10]\n",
    "\n",
    "        clf2.partial_fit(X_train_partial,y_train_partial) \n",
    "    \n",
    "    print(\"After iter # : \", iter) \n",
    "    print(clf2.coef_) \n",
    "    print()\n",
    "    print(clf2.intercept_) \n",
    "    print('-'*30)\n",
    "    iter+=1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note :**\n",
    "\n",
    "* In the first call to `partial_fit()`, we passed the list of possible target class labels. For subsequent calls to `partial_fit()`, this is not required.\n",
    "\n",
    "* Observe the changing values of the classifier attributes : `coef_` and `intercept_` which we are printing in each iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8964"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_score = clf2.score(X_test ,y_test)\n",
    "test_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's evaluate the classifier by examining the `confusion_matrix`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred = clf2.predict(X_test) \n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "ConfusionMatrixDisplay.from_predictions(y_test,y_pred)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.97      0.93      2535\n",
      "           1       0.88      0.89      0.88      2511\n",
      "           2       0.91      0.83      0.87      2454\n",
      "\n",
      "    accuracy                           0.90      7500\n",
      "   macro avg       0.90      0.90      0.90      7500\n",
      "weighted avg       0.90      0.90      0.90      7500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apart from `SGDClassifier`, we can also train `Perceptron()`, `MultinomialNB()`, in a similar manner."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **CountVectorizer vs HashingVectorizer**\n",
    "\n",
    "Vectorizers are used to convert a collection of text documents to a vector representation, thus helping in preprocessing them before applying any model on these text documents.\n",
    "\n",
    "`CountVectorizer` and `HashingVectorizer` both perform the task of vectorizing the text documents. However, there are some differences among them.\n",
    "\n",
    "* One difference is that `HashingVectorizer` does not store the resulting vocabulary (i.e. the unique tokens). Hence, it can be used to learn from data that does not fit into the computer's main memory. \n",
    "\n",
    "* Each mini-batch is vectorized using `HashingVectorizer` so as to guarantee that the input space of the estimator has always the same dimensionality.\n",
    "\n",
    "* With `HashingVectorizer`, each token directly maps to a pre-defined column position in a matrix. \n",
    "\n",
    "* For example, if there are 100 columns in the resultant (vectorized) matrix, each token (word) maps to 1 of the 100 columns. The mapping between the word and the position in matrix is done using hashing.\n",
    "\n",
    "* In other words in `HashingVectorizer`, each token transforms to a column position instead of adding to the vocabulary. \n",
    "\n",
    "Not storing the vocabulary is useful while handling large datasets. This is because holding a huge token vocabulary compromising of millions of words may be a challenging when the memory is limited.\n",
    "\n",
    "Since `HashingVectorizer` does not store vocabulary , its object not only takes lesser space, it also alleviates any dependence with function calls performed on the previous chunk of data in case of incremental learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us take some sample text documents and vectorize them, first using **CountVectorizer** and then **HashingVectorizer**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_documents = ['The well-known saying an apple a day keeps the doctor away has a very straightforward, literal meaning, that the eating of fruit maintains good health.',\n",
    "'The proverb fist appeared in print in 1866 and over 150 years later is advice that we still pass down through generation.',\n",
    "'British apples are one of the nations best loved fruit and according to Great British Apples, we consume around 122,000 tonnes of them each year.',\n",
    "'But what are the health benefits, and do they really keep the doctor away?']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **1. CountVectorizer**\n",
    "\n",
    "We will first import the library and then create an object of CountVectorizer class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count_vectorizer = CountVectorizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now use this object to vectorize the input text documents using the function `fit_transform()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_c = count_vectorizer.fit_transform(text_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 66)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_c.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, **66** is the **size of the vocabulary**.\n",
    "\n",
    "We can also see the vocabulary using `vocabulary_` attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'the': 54,\n",
       " 'well': 62,\n",
       " 'known': 36,\n",
       " 'saying': 50,\n",
       " 'an': 6,\n",
       " 'apple': 9,\n",
       " 'day': 19,\n",
       " 'keeps': 35,\n",
       " 'doctor': 21,\n",
       " 'away': 13,\n",
       " 'has': 30,\n",
       " 'very': 60,\n",
       " 'straightforward': 52,\n",
       " 'literal': 38,\n",
       " 'meaning': 41,\n",
       " 'that': 53,\n",
       " 'eating': 24,\n",
       " 'of': 43,\n",
       " 'fruit': 26,\n",
       " 'maintains': 40,\n",
       " 'good': 28,\n",
       " 'health': 31,\n",
       " 'proverb': 48,\n",
       " 'fist': 25,\n",
       " 'appeared': 8,\n",
       " 'in': 32,\n",
       " 'print': 47,\n",
       " '1866': 3,\n",
       " 'and': 7,\n",
       " 'over': 45,\n",
       " '150': 2,\n",
       " 'years': 65,\n",
       " 'later': 37,\n",
       " 'is': 33,\n",
       " 'advice': 5,\n",
       " 'we': 61,\n",
       " 'still': 51,\n",
       " 'pass': 46,\n",
       " 'down': 22,\n",
       " 'through': 57,\n",
       " 'generation': 27,\n",
       " 'british': 16,\n",
       " 'apples': 10,\n",
       " 'are': 11,\n",
       " 'one': 44,\n",
       " 'nations': 42,\n",
       " 'best': 15,\n",
       " 'loved': 39,\n",
       " 'according': 4,\n",
       " 'to': 58,\n",
       " 'great': 29,\n",
       " 'consume': 18,\n",
       " 'around': 12,\n",
       " '122': 1,\n",
       " '000': 0,\n",
       " 'tonnes': 59,\n",
       " 'them': 55,\n",
       " 'each': 23,\n",
       " 'year': 64,\n",
       " 'but': 17,\n",
       " 'what': 63,\n",
       " 'benefits': 14,\n",
       " 'do': 20,\n",
       " 'they': 56,\n",
       " 'really': 49,\n",
       " 'keep': 34}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vectorizer.vocabulary_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And **4** is the **number of text documents**. \n",
    "\n",
    "Following is the representation of four text documents :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 54)\t3\n",
      "  (0, 62)\t1\n",
      "  (0, 36)\t1\n",
      "  (0, 50)\t1\n",
      "  (0, 6)\t1\n",
      "  (0, 9)\t1\n",
      "  (0, 19)\t1\n",
      "  (0, 35)\t1\n",
      "  (0, 21)\t1\n",
      "  (0, 13)\t1\n",
      "  (0, 30)\t1\n",
      "  (0, 60)\t1\n",
      "  (0, 52)\t1\n",
      "  (0, 38)\t1\n",
      "  (0, 41)\t1\n",
      "  (0, 53)\t1\n",
      "  (0, 24)\t1\n",
      "  (0, 43)\t1\n",
      "  (0, 26)\t1\n",
      "  (0, 40)\t1\n",
      "  (0, 28)\t1\n",
      "  (0, 31)\t1\n",
      "  (1, 54)\t1\n",
      "  (1, 53)\t1\n",
      "  (1, 48)\t1\n",
      "  :\t:\n",
      "  (2, 39)\t1\n",
      "  (2, 4)\t1\n",
      "  (2, 58)\t1\n",
      "  (2, 29)\t1\n",
      "  (2, 18)\t1\n",
      "  (2, 12)\t1\n",
      "  (2, 1)\t1\n",
      "  (2, 0)\t1\n",
      "  (2, 59)\t1\n",
      "  (2, 55)\t1\n",
      "  (2, 23)\t1\n",
      "  (2, 64)\t1\n",
      "  (3, 54)\t2\n",
      "  (3, 21)\t1\n",
      "  (3, 13)\t1\n",
      "  (3, 31)\t1\n",
      "  (3, 7)\t1\n",
      "  (3, 11)\t1\n",
      "  (3, 17)\t1\n",
      "  (3, 63)\t1\n",
      "  (3, 14)\t1\n",
      "  (3, 20)\t1\n",
      "  (3, 56)\t1\n",
      "  (3, 49)\t1\n",
      "  (3, 34)\t1\n"
     ]
    }
   ],
   "source": [
    "print(X_c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **2. HashingVectorizer**\n",
    "\n",
    "Let us now see how `HashingVectorizer` is different from `CountVectorizer`.\n",
    "\n",
    "We will create an object of `HashingVectorizer`. While creating the object, we need to specify the number of features we wish to have in the feature matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "hashing_vectorizer = HashingVectorizer(n_features=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An important parameter of `HashingVectorizer` class is `n_features`. It declares the number of features (columns) in the output feature matrix.\n",
    "\n",
    "**NOTE :** Small numbers of features are likely to cause hash collisions, but large numbers will cause larger coefficient dimensions in linear learners."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's perform hashing vectorization with `fit_transform`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_h = hashing_vectorizer.fit_transform(text_documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us examine the shape of the transformed feature matrix. The number of columns in this matrix is equal to the `n_features` attribute we specified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 50)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_h.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following is the representation of the four text documents :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 5)\t0.0\n",
      "  (0, 8)\t-0.47140452079103173\n",
      "  (0, 10)\t-0.23570226039551587\n",
      "  (0, 11)\t-0.23570226039551587\n",
      "  (0, 13)\t0.0\n",
      "  (0, 18)\t-0.23570226039551587\n",
      "  (0, 20)\t0.23570226039551587\n",
      "  (0, 26)\t0.0\n",
      "  (0, 29)\t0.23570226039551587\n",
      "  (0, 33)\t0.23570226039551587\n",
      "  (0, 36)\t-0.23570226039551587\n",
      "  (0, 38)\t0.47140452079103173\n",
      "  (0, 39)\t-0.23570226039551587\n",
      "  (0, 45)\t-0.23570226039551587\n",
      "  (0, 46)\t0.23570226039551587\n"
     ]
    }
   ],
   "source": [
    "print(X_h[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**IMP :**\n",
    "\n",
    "Overall, `HashingVectorizer` is a good choice if we are falling short of memory and resources, or we need to perform incremental learning. \n",
    "\n",
    "However, `CountVectorizer` is a good choice if we need to access the actual tokens."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Demonstration**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **1. Downloading the dataset**\n",
    "\n",
    "We download a dataset from UCI ML datasets's library.\n",
    "\n",
    "Instead of downloading, unzipping and then reading, we are directly reading the zipped csv file. \n",
    "\n",
    "For that purpose, we are making use of `urllib.request`, `BytesIO` and `TextIOWrapper` classes.\n",
    "\n",
    "This is a sentiment analysis dataset. There are only two columns in the dataset. One for the textual review and the other for the sentiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import StringIO, BytesIO, TextIOWrapper \n",
    "from zipfile import ZipFile \n",
    "import urllib.request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "resp = urllib.request.urlopen('https://archive.ics.uci.edu/ml/machine-learning-databases/00331/sentiment%20labelled%20sentences.zip')\n",
    "\n",
    "zipfile = ZipFile(BytesIO(resp.read()))\n",
    "\n",
    "data = TextIOWrapper(zipfile.open('sentiment labelled sentences/amazon_cells_labelled.txt'),encoding='utf-8') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(data, sep='\\t') \n",
    "df.columns = ['review','sentiment']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **2. Exploring the dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Good case, Excellent value.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Great for the jawbone.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tied to charger for conversations lasting more...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The mic is great.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I have to jiggle the plug to get it to line up...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  sentiment\n",
       "0                        Good case, Excellent value.          1\n",
       "1                             Great for the jawbone.          1\n",
       "2  Tied to charger for conversations lasting more...          0\n",
       "3                                  The mic is great.          1\n",
       "4  I have to jiggle the plug to get it to line up...          0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 999 entries, 0 to 998\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   review     999 non-null    object\n",
      " 1   sentiment  999 non-null    int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 15.7+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>999.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.500501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.500250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        sentiment\n",
       "count  999.000000\n",
       "mean     0.500501\n",
       "std      0.500250\n",
       "min      0.000000\n",
       "25%      0.000000\n",
       "50%      1.000000\n",
       "75%      1.000000\n",
       "max      1.000000"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, \n",
    "\n",
    "* There are 999 samples in the dataset.\n",
    "\n",
    "* The possible classes for sentiment are 1 and 0.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **3. Splitting data into train and test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.loc[:,'review']\n",
    "# X2 = df.iloc[:,0]\n",
    "\n",
    "y = df.loc[:,'sentiment'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((799,), (200,), (799,), (200,))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **4. Preprocessing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import HashingVectorizer \n",
    "vectorizer = HashingVectorizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **5. Creating an instance of the SGDClassifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "classifier = SGDClassifier(penalty='l2', loss='hinge')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **6. Iteration 1 of partial_fit()**\n",
    "\n",
    "* We will assume we do not have sufficient memory to handle all the 799 samples in one go for training purpose. \n",
    "\n",
    "* So, we will take the first 400 samples from the training data and `partial_fit()` our classifier.\n",
    "\n",
    "* Another use case of `partial_fit` here could also be a scenario where we only have 400 samples available at a time. So, we fit our classifier with them. \n",
    "\n",
    "* However, we `partial_fit` it, to have the possibility of traning it with more data later whenever that becomes available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_part1_hashed = vectorizer.fit_transform(X_train[0:400])\n",
    "y_train_part1 = y_train[0:400]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need to mention all classes in the first iteration of partial_fit()\n",
    "all_classes = np.unique(df.loc[:, 'sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SGDClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SGDClassifier</label><div class=\"sk-toggleable__content\"><pre>SGDClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SGDClassifier()"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.partial_fit(X_train_part1_hashed,\n",
    "                       y_train_part1, classes=all_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us now use this classifier on our test data that we had kept aside earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first we will have to preprocess the X_test with the same vectorizer that was fit on the train data.\n",
    "X_test_hashed = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score :  0.71\n"
     ]
    }
   ],
   "source": [
    "test_score = classifier.score(X_test_hashed, y_test)\n",
    "print('Test score : ', test_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note :**\n",
    "We can also store this classifier using pickle object and can access it later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **7. Iteration 2 of partial_fit()**\n",
    "\n",
    "We will now assume that more data became available. So, we will fit the same  classifier with more data and observe if our test score improves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_part2_hashed = vectorizer.fit_transform(X_train[400:])\n",
    "y_train_part2 = y_train[400:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SGDClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SGDClassifier</label><div class=\"sk-toggleable__content\"><pre>SGDClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SGDClassifier()"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.partial_fit(X_train_part2_hashed, y_train_part2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score :  0.74\n"
     ]
    }
   ],
   "source": [
    "test_score = classifier.score(X_test_hashed, y_test)\n",
    "print('Test score : ', test_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that our test score has improved after we fed more data to the classifier in the second iteration of `partial_fit()`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('tensorflow')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "32f02dc107888b055323539767db1f9cf579f03b0ed3a3ace7986ed2d38433ec"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
